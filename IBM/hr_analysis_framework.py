# HRæ•°æ®åˆ†æä»·å€¼å‘ç°æ¡†æ¶
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

class HRValueDiscovery:
    def __init__(self, df):
        self.df = df.copy()
        self.insights = []
        self.recommendations = []
        
    def quick_business_value_scan(self):
        """å¿«é€Ÿæ‰«ææ½œåœ¨ä¸šåŠ¡ä»·å€¼ç‚¹"""
        print("=== å¿«é€Ÿä¸šåŠ¡ä»·å€¼æ‰«æ ===\n")
        
        # 1. æµå¤±ç‡åŸºæœ¬æƒ…å†µ
        attrition_rate = (self.df['Attrition'] == 'Yes').mean()
        print(f"ğŸ” æ•´ä½“æµå¤±ç‡: {attrition_rate:.2%}")
        
        if attrition_rate > 0.15:
            self.insights.append("é«˜æµå¤±ç‡è­¦å‘Š: è¶…è¿‡15%çš„å‘˜å·¥æµå¤±")
            self.recommendations.append("ä¼˜å…ˆçº§1: å»ºç«‹æµå¤±é¢„è­¦ç³»ç»Ÿ")
        
        # 2. éƒ¨é—¨æµå¤±å·®å¼‚
        dept_attrition = self.df.groupby('Department')['Attrition'].apply(
            lambda x: (x == 'Yes').mean()).sort_values(ascending=False)
        print(f"\nğŸ“Š å„éƒ¨é—¨æµå¤±ç‡:")
        print(dept_attrition.round(3))
        
        # 3. è–ªé…¬åˆ†å¸ƒå¼‚å¸¸æ£€æµ‹
        income_stats = self.df['MonthlyIncome'].describe()
        print(f"\nğŸ’° è–ªé…¬åˆ†å¸ƒ:")
        print(f"ä¸­ä½æ•°: ${income_stats['50%']:,.0f}")
        print(f"å‡å€¼: ${income_stats['mean']:,.0f}")
        
        # è–ªé…¬å·®å¼‚è¿‡å¤§æ£€æµ‹
        if income_stats['std'] / income_stats['mean'] > 0.5:
            self.insights.append("è–ªé…¬åˆ†å¸ƒä¸å‡: æ ‡å‡†å·®è¿‡å¤§ï¼Œå­˜åœ¨è–ªé…¬å…¬å¹³æ€§é—®é¢˜")
            self.recommendations.append("ä¼˜å…ˆçº§2: è–ªé…¬ä½“ç³»å®¡æŸ¥ä¸ä¼˜åŒ–")
            
        # 4. æ»¡æ„åº¦ä¸æµå¤±å…³ç³»
        satisfaction_cols = ['JobSatisfaction', 'EnvironmentSatisfaction', 
                           'RelationshipSatisfaction', 'WorkLifeBalance']
        
        for col in satisfaction_cols:
            if col in self.df.columns:
                avg_satisfaction_stay = self.df[self.df['Attrition'] == 'No'][col].mean()
                avg_satisfaction_leave = self.df[self.df['Attrition'] == 'Yes'][col].mean()
                diff = avg_satisfaction_stay - avg_satisfaction_leave
                
                if diff > 0.5:
                    self.insights.append(f"{col}æ˜¾è‘—å½±å“æµå¤±: å·®å¼‚è¾¾{diff:.2f}")
        
        return self.insights, self.recommendations
    
    def identify_high_value_segments(self):
        """è¯†åˆ«é«˜ä»·å€¼å‘˜å·¥ç¾¤ä½“å’Œé£é™©ç¾¤ä½“"""
        print("\n=== é«˜ä»·å€¼ç¾¤ä½“è¯†åˆ« ===\n")
        
        # å®šä¹‰é«˜ä»·å€¼å‘˜å·¥ï¼šé«˜ç»©æ•ˆ + é«˜è–ªé…¬ + é•¿æœŸå‘˜å·¥
        high_performers = self.df[
            (self.df['PerformanceRating'] >= 3) & 
            (self.df['MonthlyIncome'] > self.df['MonthlyIncome'].quantile(0.75)) &
            (self.df['YearsAtCompany'] >= 3)
        ]
        
        high_performer_attrition = (high_performers['Attrition'] == 'Yes').mean()
        print(f"ğŸ’ é«˜ä»·å€¼å‘˜å·¥æµå¤±ç‡: {high_performer_attrition:.2%}")
        
        if high_performer_attrition > 0.1:
            self.insights.append("å…³é”®äººæ‰æµå¤±é£é™©: é«˜ä»·å€¼å‘˜å·¥æµå¤±ç‡è¶…10%")
            self.recommendations.append("ç´§æ€¥: åˆ¶å®šå…³é”®äººæ‰ä¿ç•™è®¡åˆ’")
        
        # è¯†åˆ«é«˜é£é™©ç¾¤ä½“
        risk_factors = []
        if 'OverTime' in self.df.columns:
            overtime_attrition = self.df[self.df['OverTime'] == 'Yes']['Attrition'].apply(
                lambda x: x == 'Yes').mean()
            if overtime_attrition > 0.25:
                risk_factors.append("åŠ ç­å‘˜å·¥")
                
        print(f"ğŸ“ˆ é«˜é£é™©ç¾¤ä½“è¯†åˆ«å®Œæˆï¼Œå‘ç°{len(risk_factors)}ä¸ªé£é™©å› ç´ ")
        
    def calculate_business_impact(self):
        """è®¡ç®—æ½œåœ¨ä¸šåŠ¡å½±å“"""
        print("\n=== ä¸šåŠ¡å½±å“è®¡ç®— ===\n")
        
        total_employees = len(self.df)
        current_attrition = (self.df['Attrition'] == 'Yes').sum()
        
        # å‡è®¾æ›¿æ¢æˆæœ¬ä¸ºå¹´è–ªçš„50%
        avg_annual_salary = self.df['MonthlyIncome'].mean() * 12
        replacement_cost_per_employee = avg_annual_salary * 0.5
        
        current_cost = current_attrition * replacement_cost_per_employee
        
        print(f"ğŸ’¸ å½“å‰å¹´åº¦æµå¤±æˆæœ¬: ${current_cost:,.0f}")
        
        # å¦‚æœæµå¤±ç‡é™ä½5%çš„æ½œåœ¨èŠ‚çœ
        potential_reduction = total_employees * 0.05 * replacement_cost_per_employee
        print(f"ğŸ’° æµå¤±ç‡é™ä½5%çš„æ½œåœ¨èŠ‚çœ: ${potential_reduction:,.0f}")
        
        self.insights.append(f"å¹´åº¦æµå¤±æˆæœ¬çº¦${current_cost/1000000:.1f}M")
        self.recommendations.append(f"ç›®æ ‡: é€šè¿‡æ•°æ®é©±åŠ¨ç­–ç•¥èŠ‚çœ${potential_reduction/1000000:.1f}M")
        
    def generate_actionable_insights(self):
        """ç”Ÿæˆå¯æ‰§è¡Œçš„æ´å¯Ÿå»ºè®®"""
        print("\n=== å¯æ‰§è¡Œæ´å¯Ÿä¸å»ºè®® ===\n")
        
        # ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆç”¨äºæŒ‡å¯¼è¡ŒåŠ¨æ–¹å‘ï¼‰
        X = self.df.drop('Attrition', axis=1)
        y = self.df['Attrition'].map({'Yes': 1, 'No': 0})
        
        # å¤„ç†åˆ†ç±»å˜é‡
        categorical_columns = X.select_dtypes(include=['object']).columns
        X_encoded = X.copy()
        
        for col in categorical_columns:
            le = LabelEncoder()
            X_encoded[col] = le.fit_transform(X[col])
        
        # è®­ç»ƒç®€å•æ¨¡å‹è·å–ç‰¹å¾é‡è¦æ€§
        rf = RandomForestClassifier(n_estimators=100, random_state=42)
        rf.fit(X_encoded, y)
        
        feature_importance = pd.DataFrame({
            'feature': X_encoded.columns,
            'importance': rf.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("ğŸ¯ å½±å“æµå¤±çš„TOP5å› ç´ :")
        top_5_features = feature_importance.head(5)
        for idx, row in top_5_features.iterrows():
            print(f"   {row['feature']}: {row['importance']:.3f}")
            
        # åŸºäºTOPç‰¹å¾ç”Ÿæˆå…·ä½“å»ºè®®
        top_feature = top_5_features.iloc[0]['feature']
        
        action_map = {
            'MonthlyIncome': "è–ªé…¬è°ƒæ•´ï¼šå»ºç«‹åŸºäºå¸‚åœºçš„è–ªé…¬ä½“ç³»",
            'Age': "å¹´é¾„ç®¡ç†ï¼šå…³æ³¨ä¸åŒå¹´é¾„æ®µå‘˜å·¥éœ€æ±‚",
            'JobSatisfaction': "æ»¡æ„åº¦æå‡ï¼šæ”¹å–„å·¥ä½œå†…å®¹å’Œç¯å¢ƒ",
            'WorkLifeBalance': "å¹³è¡¡æ”¿ç­–ï¼šæ¨è¡Œå¼¹æ€§å·¥ä½œåˆ¶åº¦",
            'YearsAtCompany': "èŒä¸šå‘å±•ï¼šå»ºç«‹æ˜ç¡®çš„æ™‹å‡é€šé“"
        }
        
        if top_feature in action_map:
            self.recommendations.append(f"æ ¸å¿ƒè¡ŒåŠ¨: {action_map[top_feature]}")
    
    def create_value_proposition(self):
        """åˆ›å»ºä»·å€¼ä¸»å¼ æŠ¥å‘Š"""
        print("\n" + "="*50)
        print("           æ•°æ®é©±åŠ¨HRä¼˜åŒ–ä»·å€¼ä¸»å¼ ")
        print("="*50)
        
        print("\nğŸ” æ ¸å¿ƒå‘ç°:")
        for i, insight in enumerate(self.insights, 1):
            print(f"   {i}. {insight}")
            
        print("\nğŸ¯ æ¨èè¡ŒåŠ¨:")
        for i, rec in enumerate(self.recommendations, 1):
            print(f"   {i}. {rec}")
            
        print("\nğŸ“Š å»ºè®®çš„åˆ†æäº§å“:")
        products = [
            "å‘˜å·¥æµå¤±é£é™©é¢„è­¦ä»ªè¡¨æ¿",
            "è–ªé…¬å…¬å¹³æ€§åˆ†ææŠ¥å‘Š", 
            "éƒ¨é—¨ç»©æ•ˆå¯¹æ¯”åˆ†æ",
            "å‘˜å·¥æ»¡æ„åº¦æ”¹å–„è·¯å¾„å›¾",
            "é«˜æ½œäººæ‰è¯†åˆ«ä¸å‘å±•è®¡åˆ’"
        ]
        
        for i, product in enumerate(products, 1):
            print(f"   {i}. {product}")
            
        return self.insights, self.recommendations

# ä½¿ç”¨ç¤ºä¾‹
def analyze_hr_dataset(df):
    """å®Œæ•´çš„HRæ•°æ®é›†ä»·å€¼å‘ç°æµç¨‹"""
    analyzer = HRValueDiscovery(df)
    
    # æ‰§è¡Œåˆ†æ
    analyzer.quick_business_value_scan()
    analyzer.identify_high_value_segments()
    analyzer.calculate_business_impact() 
    analyzer.generate_actionable_insights()
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    insights, recommendations = analyzer.create_value_proposition()
    
    return insights, recommendations

# å¦‚æœæœ‰æ•°æ®é›†ï¼Œè¿è¡Œåˆ†æï¼š
# insights, recs = analyze_hr_dataset(your_df)