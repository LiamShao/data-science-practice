# -*- coding: utf-8 -*-
"""kt-v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10Jb5qCPbYtwH3J6TJ9732zmFsPDw7xRd
"""

import os

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import seaborn as sns

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
# pd.set_option('max_rows', None)
pd.options.display.max_rows = None

# Commented out IPython magic to ensure Python compatibility.
# %config Completer.use_jedi = False

from google.colab import drive
drive.mount('/content/drive')

train_df = pd.read_csv('/content/drive/MyDrive/GCI/titanic/train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/GCI/titanic/test.csv')

train_df.head()

"""EDA"""

def plot_missing_data(dataset, title):
    fig, ax = plt.subplots(figsize=(5,5))
    plt.title(title)
    sns.heatmap(dataset.isnull(), cbar=False)

train_df.info()

plot_missing_data(train_df, "Training Dataset")

test_df.info()

plot_missing_data(test_df, "Test Dataset")

def bar_chart_stacked(dataset, feature, stacked = True):
    survived = dataset[dataset['Survived']==1][feature].value_counts()
    dead = dataset[dataset['Survived']==0][feature].value_counts()
    df_survived_dead = pd.DataFrame([survived,dead])
    df_survived_dead.index = ['Passengers Survived','Passengers Died']
    ax = df_survived_dead.plot(kind='bar',stacked=stacked, figsize=(5,5))

train_df['Survived'].value_counts()

train_df['Survived'].value_counts(normalize=True)

bar_chart_stacked(train_df, "Survived")

train_df['Sex'].value_counts().to_frame()

bar_chart_stacked(train_df, "Sex")

train_df.groupby('Sex').Survived.mean()

bar_chart_stacked(train_df, 'Pclass')

pd.pivot_table(train_df, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count')

train_df.groupby(['Pclass']).Survived.mean().to_frame()

def bar_chart_compare(dataset, feature1, feature2=None, title = "Survival rate by sex and class'"):
    plt.figure(figsize = [5,5])
    plt.title(title)
    g = sns.barplot(x=feature1, y='Survived', hue=feature2, ci=None, data=dataset).set_ylabel('Survival rate')

bar_chart_compare(train_df, "Pclass", "Sex")

pd.pivot_table(train_df, index = 'Survived', columns = ['Pclass', "Sex"], values = 'Ticket' ,aggfunc ='count')

train_df.groupby(['Pclass', "Sex"]).Survived.mean().to_frame()

def plot_distribution(dataset, feature, title, bins = 30, hist = True, fsize = (5,5)):
    fig, ax = plt.subplots(figsize=fsize)
    ax.set_title(title)
    sns.distplot(train_df[feature], color='g', bins=bins, ax=ax)

def plot_kernel_density_estimate_survivors(dataset, feature1, title, fsize = (5,5)):
    fig, ax = plt.subplots(figsize=fsize)
    ax.set_title(title)
    sns.kdeplot(dataset[feature1].loc[train_df["Survived"] == 1],
                shade= True, ax=ax, label='Survived').set_xlabel(feature1)
    sns.kdeplot(dataset[feature1].loc[train_df["Survived"] == 0],
                shade=True, ax=ax, label="Died")

plot_distribution(train_df, "Age", "Age Distribution Passengers")

plot_kernel_density_estimate_survivors(train_df, "Age", "Age Distribution Surived vs Died")

def plot_swarm_survivors(dataset, feature1, feature2, title, fize = (155)):
    fig, ax = plt.subplots(figsize=(18,5))
    # Turns off grid on the left Axis.
    ax.grid(True)
    plt.xticks(list(range(0,100,2)))
    sns.swarmplot(y=feature1, x=feature2, hue='Survived',data=train_df).set_title(title)

plot_swarm_survivors(train_df, "Sex", "Age", "Survivor Swarmplot for Age and Gender")

plot_swarm_survivors(train_df, "Age", "Pclass", "Survivor Swarmplot for Age and Gender")

train_df.Fare.describe()

plot_distribution(train_df, "Fare", "Fare Distribution Passengers")

def plot_quartiles(dataset, feature, title, categories):
    fig, axarr = plt.subplots(figsize=(5,5))
    fare_ranges = pd.qcut(dataset[feature], len(categories), labels = categories) #. [0, .25, .5, .75, 1.]
    axarr.set_title(title)
    sns.barplot(x=fare_ranges, y=dataset.Survived, ci=None, ax=axarr).set_ylabel('Survival rate')

categories = ['Cheap', 'Standard', 'Expensive', 'Luxury']

plot_quartiles(train_df, "Fare", "Survival Rate by Fare Ranges/Categories", categories)

plot_swarm_survivors(train_df, "Fare", "Sex","Survivor Swarmplot for Age and Gender")

train_df.loc[train_df.Fare==0]

len(train_df.loc[train_df.Fare==0])

# Replace Fare == 0 with nan
train_df.loc[train_df['Fare'] == 0, 'Fare'] = np.nan
test_df.loc[train_df['Fare'] == 0, 'Fare'] = np.nan

def show_countplot(dataset, feature, title, fsize = (5,5)):
    fig, ax = plt.subplots(figsize=fsize)
    sns.countplot(dataset[feature], ax=ax).set_title(title)

def show_compare_countplot(dataset, feature1, feature2, title):
    fig, ax = plt.subplots(figsize=(5,5))
    p = sns.countplot(x = feature1, hue = feature2, data = dataset, ax=ax).set_title(title)

bar_chart_stacked(train_df, 'Embarked')

show_countplot(train_df, "Embarked", 'Passengers count by boarding point')

train_df['Embarked'].value_counts().to_frame()

show_compare_countplot(train_df, "Embarked", "Survived", "Survivor count by place of embarktion")

pd.pivot_table(train_df, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count')

train_df.groupby(['Embarked']).Survived.mean().to_frame()

show_compare_countplot(train_df, "Embarked", "Pclass", "Passenger count by place of embarktion and class")

train_df.groupby(['Embarked', 'Pclass']).Survived.sum().to_frame()

"""Feature engineering"""

pd.unique(train_df['Name'])

train_df['Title'] = train_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())
test_df['Title'] = test_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())

train_df.head()

train_df['Title'].value_counts().to_frame()

show_countplot(train_df, "Title", 'Title Distribution', (15,3))

train_df['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)
test_df['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)
train_df['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)
test_df['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)

show_countplot(train_df, "Title", 'Title Distribution after substitution', (15,3))

train_df[['Cabin', 'Ticket']]

# Extract Leading Letter:
train_df['Ticket_2letter'] = train_df.Ticket.apply(lambda x: x[:2])
test_df['Ticket_2letter'] = test_df.Ticket.apply(lambda x: x[:2])

# Extract Ticket Lenght:
train_df['Ticket_len'] = train_df.Ticket.apply(lambda x: len(x))
test_df['Ticket_len'] = test_df.Ticket.apply(lambda x: len(x))

# Extract Number of Cabins:
train_df['Cabin_num'] = train_df.Ticket.apply(lambda x: len(x.split()))
test_df['Cabin_num'] = test_df.Ticket.apply(lambda x: len(x.split()))

# Extract Leading Letter:
train_df['Cabin_1letter'] = train_df.Ticket.apply(lambda x: x[:1])
test_df['Cabin_1letter'] = test_df.Ticket.apply(lambda x: x[:1])

len(train_df['Ticket'].value_counts().to_frame())

len(train_df["Ticket_2letter"].value_counts().to_frame())

len(train_df["Ticket_len"].value_counts().to_frame())

train_df.head()

len(train_df['Cabin'].value_counts().to_frame())

len(train_df['Cabin_num'].value_counts().to_frame())

train_df['Cabin_num'].value_counts().to_frame()

len(train_df['Cabin_1letter'].value_counts().to_frame())

train_df['Fam_size'] = train_df['SibSp'] + train_df['Parch'] + 1
test_df['Fam_size'] = test_df['SibSp'] + test_df['Parch'] + 1

# Creation of four groups
train_df['Fam_type'] = pd.cut(train_df.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])
test_df['Fam_type'] = pd.cut(test_df.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])

y = train_df['Survived']
features = ['Pclass', 'Fare', 'Title', 'Embarked', 'Fam_type', 'Ticket_len', 'Ticket_2letter']
X = train_df[features]
X.head()

numerical_cols = ['Fare']
categorical_cols = ['Pclass', 'Title', 'Embarked', 'Fam_type', 'Ticket_len', 'Ticket_2letter']

# Inputing numerical values with median
numerical_transformer = SimpleImputer(strategy='median')

# Inputing missing values with most frequent one for categorical data
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Bundle preprocessing for numerical and categorical data
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Bundle preprocessing and modeling code
titanic_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', RandomForestClassifier(random_state=0, n_estimators=500, max_depth=5))
])

# Training
titanic_pipeline.fit(X,y)

print('Cross validation score: {:.3f}'.format(cross_val_score(titanic_pipeline, X, y, cv=10).mean()))

X_test = test_df[features]
X_test.head()

predictions = titanic_pipeline.predict(X_test)

output = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': predictions})
output.to_csv('get_in_top3.csv', index=False)