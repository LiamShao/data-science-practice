# =====================================
# POSä¸šåŠ¡æ•°æ®åˆ†æ - é¡¶çº§æ•°æ®ç§‘å­¦å®¶æ–¹æ³•
# =====================================

# 1. ç¯å¢ƒé…ç½®å’Œåº“å¯¼å…¥
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import pearsonr, spearmanr
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾è¡¨æ ·å¼
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
plt.style.use('seaborn-v0_8')

print("ğŸ“Š POSä¸šåŠ¡æ•°æ®åˆ†æç³»ç»Ÿ")
print("=" * 50)
print("ğŸ”¬ åŸºäºé¡¶çº§æ•°æ®ç§‘å­¦å®¶æ–¹æ³•è®º")
print("ğŸ“ˆ ç›®æ ‡ï¼šæŒ–æ˜å•†ä¸šä»·å€¼ï¼Œä¼˜åŒ–ä¸šåŠ¡å†³ç­–")
print("=" * 50)

# 2. æ•°æ®åŠ è½½å’Œåˆæ­¥æ£€æŸ¥
class DataLoader:
    def __init__(self):
        self.data = {}
        self.data_quality = {}
    
    def load_all_data(self):
        """åŠ è½½æ‰€æœ‰æ•°æ®æ–‡ä»¶"""
        print("\nğŸ“¥ åŠ è½½æ•°æ®æ–‡ä»¶...")
        
        # åŠ è½½å„ä¸ªæ•°æ®æ–‡ä»¶
        try:
            # å®¢æœç”µè¯æ•°æ®
            self.data['call'] = pd.read_csv('regi_call_data_transform .csv')
            self.data['call']['cdr_date'] = pd.to_datetime(self.data['call']['cdr_date'])
            print(f"âœ… å®¢æœç”µè¯æ•°æ®: {len(self.data['call'])} rows")
            
            # è´¦æˆ·è·å–æ•°æ®
            self.data['account'] = pd.read_csv('regi_acc_get_data_transform .csv')
            self.data['account']['cdr_date'] = pd.to_datetime(self.data['account']['cdr_date'])
            print(f"âœ… è´¦æˆ·è·å–æ•°æ®: {len(self.data['account'])} rows")
            
            # è¥é”€æŠ•æ”¾æ•°æ®
            self.data['campaign'] = pd.read_csv('cm_data .csv')
            self.data['campaign']['cdr_date'] = pd.to_datetime(self.data['campaign']['cdr_date'])
            print(f"âœ… è¥é”€æŠ•æ”¾æ•°æ®: {len(self.data['campaign'])} rows")
            
            # æœç´¢è¶‹åŠ¿æ•°æ®
            self.data['search'] = pd.read_csv('gt_service_name .csv')
            self.data['search']['week'] = pd.to_datetime(self.data['search']['week'])
            print(f"âœ… æœç´¢è¶‹åŠ¿æ•°æ®: {len(self.data['search'])} rows")
            
            # æ—¥å†æ•°æ®
            self.data['calendar'] = pd.read_csv('calender_data .csv')
            self.data['calendar']['cdr_date'] = pd.to_datetime(self.data['calendar']['cdr_date'])
            print(f"âœ… æ—¥å†æ•°æ®: {len(self.data['calendar'])} rows")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def check_data_quality(self):
        """æ£€æŸ¥æ•°æ®è´¨é‡"""
        print("\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥...")
        
        for name, df in self.data.items():
            if df is not None:
                missing_rate = df.isnull().sum().sum() / (df.shape[0] * df.shape[1])
                date_range = None
                
                if name == 'search':
                    date_range = (df['week'].min(), df['week'].max())
                elif 'cdr_date' in df.columns:
                    date_range = (df['cdr_date'].min(), df['cdr_date'].max())
                
                self.data_quality[name] = {
                    'missing_rate': missing_rate,
                    'date_range': date_range,
                    'shape': df.shape
                }
                
                print(f"ğŸ“Š {name}: ç¼ºå¤±ç‡={missing_rate:.2%}, æ—¶é—´èŒƒå›´={date_range}")
        
        return self.data_quality

# 3. æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹
class DataPreprocessor:
    def __init__(self, data):
        self.data = data
        self.master_data = None
    
    def create_master_dataset(self):
        """åˆ›å»ºä¸»æ•°æ®é›†"""
        print("\nğŸ”§ åˆ›å»ºä¸»æ•°æ®é›†...")
        
        # ä»¥æ—¥å†æ•°æ®ä¸ºåŸºç¡€
        master = self.data['calendar'].copy()
        
        # åˆå¹¶å®¢æœç”µè¯æ•°æ®
        master = master.merge(
            self.data['call'], 
            on='cdr_date', 
            how='left'
        )
        
        # åˆå¹¶è´¦æˆ·è·å–æ•°æ®
        master = master.merge(
            self.data['account'], 
            on='cdr_date', 
            how='left'
        )
        
        # åˆå¹¶è¥é”€æŠ•æ”¾æ•°æ®
        master = master.merge(
            self.data['campaign'], 
            on='cdr_date', 
            how='left'
        )
        
        # å¤„ç†æœç´¢æ•°æ®ï¼ˆå‘¨åº¦è½¬æ—¥åº¦ï¼‰
        search_daily = self.convert_weekly_to_daily(self.data['search'])
        master = master.merge(
            search_daily, 
            on='cdr_date', 
            how='left'
        )
        
        # å¡«å……ç¼ºå¤±å€¼
        master['call_num'] = master['call_num'].fillna(0)
        master['acc_get_cnt'] = master['acc_get_cnt'].fillna(0)
        master['cm_flg'] = master['cm_flg'].fillna(0)
        master['search_cnt'] = master['search_cnt'].fillna(master['search_cnt'].mean())
        
        print(f"âœ… ä¸»æ•°æ®é›†åˆ›å»ºå®Œæˆ: {master.shape}")
        self.master_data = master
        return master
    
    def convert_weekly_to_daily(self, weekly_data):
        """å°†å‘¨åº¦æ•°æ®è½¬æ¢ä¸ºæ—¥åº¦æ•°æ®"""
        daily_search = []
        
        for _, row in weekly_data.iterrows():
            week_start = row['week']
            search_cnt = row['search_cnt']
            
            # ä¸ºè¿™ä¸€å‘¨çš„æ¯ä¸€å¤©åˆ†é…æœç´¢é‡
            for i in range(7):
                daily_search.append({
                    'cdr_date': week_start + timedelta(days=i),
                    'search_cnt': search_cnt
                })
        
        return pd.DataFrame(daily_search)
    
    def create_features(self):
        """åˆ›å»ºç‰¹å¾å˜é‡"""
        print("\nâš™ï¸ åˆ›å»ºç‰¹å¾å˜é‡...")
        
        df = self.master_data.copy()
        
        # æ—¶é—´ç‰¹å¾
        df['year'] = df['cdr_date'].dt.year
        df['month'] = df['cdr_date'].dt.month
        df['day'] = df['cdr_date'].dt.day
        df['weekday'] = df['cdr_date'].dt.weekday
        df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)
        
        # æ»åç‰¹å¾
        df['acc_get_cnt_lag1'] = df['acc_get_cnt'].shift(1)
        df['acc_get_cnt_lag3'] = df['acc_get_cnt'].shift(3)
        df['acc_get_cnt_lag7'] = df['acc_get_cnt'].shift(7)
        
        df['call_num_lag1'] = df['call_num'].shift(1)
        df['call_num_lag3'] = df['call_num'].shift(3)
        df['call_num_lag7'] = df['call_num'].shift(7)
        
        # ç§»åŠ¨å¹³å‡ç‰¹å¾
        df['acc_get_cnt_ma7'] = df['acc_get_cnt'].rolling(window=7).mean()
        df['acc_get_cnt_ma30'] = df['acc_get_cnt'].rolling(window=30).mean()
        
        df['call_num_ma7'] = df['call_num'].rolling(window=7).mean()
        df['call_num_ma30'] = df['call_num'].rolling(window=30).mean()
        
        # è¥é”€æ´»åŠ¨ç‰¹å¾
        df['cm_flg_lag1'] = df['cm_flg'].shift(1)
        df['cm_flg_lag3'] = df['cm_flg'].shift(3)
        df['cm_flg_lag7'] = df['cm_flg'].shift(7)
        
        # ç´¯è®¡è¥é”€æ•ˆæœ
        df['cm_cumulative_7d'] = df['cm_flg'].rolling(window=7).sum()
        df['cm_cumulative_30d'] = df['cm_flg'].rolling(window=30).sum()
        
        print(f"âœ… ç‰¹å¾åˆ›å»ºå®Œæˆ: {df.shape[1]} ä¸ªç‰¹å¾")
        self.master_data = df
        return df

# 4. æ ¸å¿ƒä¸šåŠ¡åˆ†æç±»
class BusinessAnalyzer:
    def __init__(self, data):
        self.data = data
        self.insights = {}
    
    def analyze_marketing_effectiveness(self):
        """è¥é”€æ•ˆæœåˆ†æ"""
        print("\nğŸ¯ è¥é”€æ•ˆæœåˆ†æ")
        print("=" * 40)
        
        # 1. åŸºç¡€ç»Ÿè®¡
        campaign_days = self.data[self.data['cm_flg'] == 1]
        no_campaign_days = self.data[self.data['cm_flg'] == 0]
        
        avg_acquisition_campaign = campaign_days['acc_get_cnt'].mean()
        avg_acquisition_no_campaign = no_campaign_days['acc_get_cnt'].mean()
        
        # 2. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
        t_stat, p_value = stats.ttest_ind(
            campaign_days['acc_get_cnt'].dropna(),
            no_campaign_days['acc_get_cnt'].dropna()
        )
        
        # 3. æ•ˆæœé‡åŒ–
        lift = (avg_acquisition_campaign - avg_acquisition_no_campaign) / avg_acquisition_no_campaign
        
        insights = {
            'avg_acquisition_campaign': avg_acquisition_campaign,
            'avg_acquisition_no_campaign': avg_acquisition_no_campaign,
            'absolute_lift': avg_acquisition_campaign - avg_acquisition_no_campaign,
            'relative_lift': lift,
            'statistical_significance': p_value,
            'campaign_days': len(campaign_days),
            'total_days': len(self.data)
        }
        
        print(f"ğŸ“Š è¥é”€æŠ•æ”¾æœŸé—´æ—¥å‡è·å®¢: {avg_acquisition_campaign:.1f}")
        print(f"ğŸ“Š éæŠ•æ”¾æœŸé—´æ—¥å‡è·å®¢: {avg_acquisition_no_campaign:.1f}")
        print(f"ğŸ“ˆ ç»å¯¹æå‡: {insights['absolute_lift']:.1f} ä¸ªå®¢æˆ·/å¤©")
        print(f"ğŸ“ˆ ç›¸å¯¹æå‡: {lift:.1%}")
        print(f"ğŸ”¬ ç»Ÿè®¡æ˜¾è‘—æ€§: p={p_value:.4f}")
        
        # 4. æŠ•æ”¾æ—¶æœºåˆ†æ
        campaign_by_weekday = self.data[self.data['cm_flg'] == 1].groupby('weekday')['acc_get_cnt'].mean()
        
        print(f"\nğŸ“… ä¸åŒæ˜ŸæœŸæŠ•æ”¾æ•ˆæœ:")
        weekday_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
        for day, avg in campaign_by_weekday.items():
            print(f"   {weekday_names[day]}: {avg:.1f} ä¸ªå®¢æˆ·/å¤©")
        
        self.insights['marketing'] = insights
        return insights
    
    def analyze_customer_service_patterns(self):
        """å®¢æœéœ€æ±‚æ¨¡å¼åˆ†æ"""
        print("\nğŸ“ å®¢æœéœ€æ±‚æ¨¡å¼åˆ†æ")
        print("=" * 40)
        
        # 1. å‘¨åº¦æ¨¡å¼
        weekly_pattern = self.data.groupby('weekday')['call_num'].mean()
        weekly_pattern_normalized = weekly_pattern / weekly_pattern.mean()
        
        # 2. æœˆåº¦æ¨¡å¼
        monthly_pattern = self.data.groupby(self.data['cdr_date'].dt.day)['call_num'].mean()
        
        # 3. èŠ‚å‡æ—¥æ•ˆåº”
        holiday_effect = self.data.groupby('holiday_flag')['call_num'].mean()
        before_holiday_effect = self.data.groupby('day_before_holiday_flag')['call_num'].mean()
        
        # 4. å­£èŠ‚æ€§æ¨¡å¼
        seasonal_pattern = self.data.groupby('month')['call_num'].mean()
        
        insights = {
            'weekly_pattern': weekly_pattern_normalized.to_dict(),
            'holiday_effect': holiday_effect.to_dict(),
            'before_holiday_effect': before_holiday_effect.to_dict(),
            'seasonal_pattern': seasonal_pattern.to_dict(),
            'avg_daily_calls': self.data['call_num'].mean(),
            'peak_day': weekly_pattern.idxmax(),
            'low_day': weekly_pattern.idxmin()
        }
        
        print(f"ğŸ“Š æ—¥å‡å®¢æœç”µè¯: {insights['avg_daily_calls']:.1f}")
        print(f"ğŸ“ˆ é«˜å³°æ—¥: {['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'][insights['peak_day']]}")
        print(f"ğŸ“‰ ä½è°·æ—¥: {['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'][insights['low_day']]}")
        
        weekday_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
        print(f"\nğŸ“… å‘¨åº¦éœ€æ±‚æ¨¡å¼:")
        for day, multiplier in weekly_pattern_normalized.items():
            print(f"   {weekday_names[day]}: {multiplier:.2f}x (æ¯”å¹³å‡{(multiplier-1)*100:+.0f}%)")
        
        if True in insights['holiday_effect']:
            holiday_multiplier = insights['holiday_effect'][True] / insights['holiday_effect'][False]
            print(f"ğŸŒ èŠ‚å‡æ—¥æ•ˆåº”: {holiday_multiplier:.2f}x")
        
        self.insights['customer_service'] = insights
        return insights
    
    def analyze_search_business_correlation(self):
        """æœç´¢è¶‹åŠ¿ä¸ä¸šåŠ¡å…³è”åˆ†æ"""
        print("\nğŸ” æœç´¢è¶‹åŠ¿ä¸ä¸šåŠ¡å…³è”åˆ†æ")
        print("=" * 40)
        
        # è¿‡æ»¤æ‰ç¼ºå¤±å€¼
        valid_data = self.data.dropna(subset=['search_cnt', 'acc_get_cnt'])
        
        if len(valid_data) < 10:
            print("âŒ æœ‰æ•ˆæ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå…³è”åˆ†æ")
            return {}
        
        # 1. å½“æœŸç›¸å…³æ€§
        corr_current, p_current = pearsonr(valid_data['search_cnt'], valid_data['acc_get_cnt'])
        
        # 2. æ»åç›¸å…³æ€§åˆ†æ
        lag_correlations = {}
        for lag in range(1, 8):  # 1-7å¤©æ»å
            if len(valid_data) > lag:
                search_lag = valid_data['search_cnt'].shift(lag)
                mask = ~(search_lag.isna() | valid_data['acc_get_cnt'].isna())
                if mask.sum() > 10:
                    corr_lag, p_lag = pearsonr(search_lag[mask], valid_data['acc_get_cnt'][mask])
                    lag_correlations[lag] = {'correlation': corr_lag, 'p_value': p_lag}
        
        # 3. æ‰¾å‡ºæœ€ä½³æ»åæœŸ
        best_lag = 0
        best_corr = abs(corr_current)
        
        for lag, stats in lag_correlations.items():
            if abs(stats['correlation']) > best_corr:
                best_corr = abs(stats['correlation'])
                best_lag = lag
        
        insights = {
            'current_correlation': corr_current,
            'current_p_value': p_current,
            'lag_correlations': lag_correlations,
            'best_lag': best_lag,
            'best_correlation': best_corr,
            'search_mean': valid_data['search_cnt'].mean(),
            'search_std': valid_data['search_cnt'].std()
        }
        
        print(f"ğŸ“Š å½“æœŸç›¸å…³æ€§: {corr_current:.3f} (p={p_current:.4f})")
        print(f"ğŸ“ˆ æœ€ä½³æ»åæœŸ: {best_lag} å¤©")
        print(f"ğŸ“ˆ æœ€ä½³ç›¸å…³æ€§: {best_corr:.3f}")
        
        if best_lag > 0:
            print(f"ğŸ’¡ æ´å¯Ÿ: æœç´¢é‡é¢†å…ˆä¸šåŠ¡æŒ‡æ ‡ {best_lag} å¤©")
        
        self.insights['search_correlation'] = insights
        return insights
    
    def build_prediction_models(self):
        """æ„å»ºé¢„æµ‹æ¨¡å‹"""
        print("\nğŸ¤– æ„å»ºé¢„æµ‹æ¨¡å‹")
        print("=" * 40)
        
        # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
        feature_cols = [
            'dow', 'woy', 'wom', 'doy', 'is_weekend',
            'holiday_flag', 'day_before_holiday_flag',
            'cm_flg', 'cm_flg_lag1', 'cm_flg_lag3', 'cm_flg_lag7',
            'search_cnt', 'acc_get_cnt_lag1', 'acc_get_cnt_lag3', 'acc_get_cnt_lag7',
            'call_num_lag1', 'call_num_lag3', 'call_num_lag7'
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„ç‰¹å¾
        available_features = [col for col in feature_cols if col in self.data.columns]
        
        # 1. å®¢æœéœ€æ±‚é¢„æµ‹æ¨¡å‹
        call_model_results = self.build_call_prediction_model(available_features)
        
        # 2. è´¦æˆ·è·å–é¢„æµ‹æ¨¡å‹
        account_model_results = self.build_account_prediction_model(available_features)
        
        insights = {
            'call_prediction': call_model_results,
            'account_prediction': account_model_results,
            'features_used': available_features
        }
        
        self.insights['prediction_models'] = insights
        return insights
    
    def build_call_prediction_model(self, features):
        """æ„å»ºå®¢æœéœ€æ±‚é¢„æµ‹æ¨¡å‹"""
        print("ğŸ“ å®¢æœéœ€æ±‚é¢„æµ‹æ¨¡å‹...")
        
        # å‡†å¤‡æ•°æ®
        model_data = self.data[features + ['call_num']].dropna()
        
        if len(model_data) < 50:
            print("âŒ æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ„å»ºæ¨¡å‹")
            return {}
        
        X = model_data[features]
        y = model_data['call_num']
        
        # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, shuffle=False
        )
        
        # è®­ç»ƒæ¨¡å‹
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        
        # é¢„æµ‹å’Œè¯„ä¼°
        y_pred = model.predict(X_test)
        
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
        
        # ç‰¹å¾é‡è¦æ€§
        feature_importance = dict(zip(features, model.feature_importances_))
        top_features = dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:5])
        
        results = {
            'mae': mae,
            'rmse': rmse,
            'mape': mape,
            'feature_importance': top_features,
            'model_score': model.score(X_test, y_test),
            'sample_size': len(model_data)
        }
        
        print(f"   MAE: {mae:.2f}")
        print(f"   RMSE: {rmse:.2f}")
        print(f"   MAPE: {mape:.1f}%")
        print(f"   RÂ²: {results['model_score']:.3f}")
        
        return results
    
    def build_account_prediction_model(self, features):
        """æ„å»ºè´¦æˆ·è·å–é¢„æµ‹æ¨¡å‹"""
        print("ğŸ‘¥ è´¦æˆ·è·å–é¢„æµ‹æ¨¡å‹...")
        
        # å‡†å¤‡æ•°æ®
        model_data = self.data[features + ['acc_get_cnt']].dropna()
        
        if len(model_data) < 50:
            print("âŒ æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ„å»ºæ¨¡å‹")
            return {}
        
        X = model_data[features]
        y = model_data['acc_get_cnt']
        
        # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, shuffle=False
        )
        
        # è®­ç»ƒæ¨¡å‹
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        
        # é¢„æµ‹å’Œè¯„ä¼°
        y_pred = model.predict(X_test)
        
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
        
        # ç‰¹å¾é‡è¦æ€§
        feature_importance = dict(zip(features, model.feature_importances_))
        top_features = dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:5])
        
        results = {
            'mae': mae,
            'rmse': rmse,
            'mape': mape,
            'feature_importance': top_features,
            'model_score': model.score(X_test, y_test),
            'sample_size': len(model_data)
        }
        
        print(f"   MAE: {mae:.2f}")
        print(f"   RMSE: {rmse:.2f}")
        print(f"   MAPE: {mape:.1f}%")
        print(f"   RÂ²: {results['model_score']:.3f}")
        
        return results

# 5. å¯è§†åŒ–åˆ†æç±»
class BusinessVisualizer:
    def __init__(self, data, insights):
        self.data = data
        self.insights = insights
    
    def create_comprehensive_dashboard(self):
        """åˆ›å»ºç»¼åˆåˆ†æä»ªè¡¨æ¿"""
        print("\nğŸ“Š åˆ›å»ºç»¼åˆåˆ†æä»ªè¡¨æ¿...")
        
        # åˆ›å»ºå¤§å›¾è¡¨
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        fig.suptitle('POS Business Analytics Dashboard', fontsize=16, fontweight='bold')
        
        # 1. æ—¶é—´åºåˆ—è¶‹åŠ¿
        self.plot_time_series_trends(axes[0, 0])
        
        # 2. è¥é”€æ•ˆæœåˆ†æ
        self.plot_marketing_effectiveness(axes[0, 1])
        
        # 3. å®¢æœéœ€æ±‚æ¨¡å¼
        self.plot_service_patterns(axes[0, 2])
        
        # 4. æœç´¢è¶‹åŠ¿å…³è”
        self.plot_search_correlation(axes[1, 0])
        
        # 5. é¢„æµ‹æ¨¡å‹è¡¨ç°
        self.plot_model_performance(axes[1, 1])
        
        # 6. å…³é”®æŒ‡æ ‡æ€»è§ˆ
        self.plot_key_metrics_summary(axes[1, 2])
        
        plt.tight_layout()
        plt.show()
        
        return fig
    
    def plot_time_series_trends(self, ax):
        """ç»˜åˆ¶æ—¶é—´åºåˆ—è¶‹åŠ¿"""
        ax.set_title('Business Metrics Time Series', fontweight='bold')
        
        # åˆ›å»ºåŒyè½´
        ax2 = ax.twinx()
        
        # å·¦è½´ï¼šè´¦æˆ·è·å–æ•°
        line1 = ax.plot(self.data['cdr_date'], self.data['acc_get_cnt'], 
                       color='blue', label='Account Acquisition', linewidth=2)
        ax.set_ylabel('Account Acquisition', color='blue')
        ax.tick_params(axis='y', labelcolor='blue')
        
        # å³è½´ï¼šå®¢æœç”µè¯æ•°
        line2 = ax2.plot(self.data['cdr_date'], self.data['call_num'], 
                        color='red', label='Service Calls', linewidth=2, alpha=0.7)
        ax2.set_ylabel('Service Calls', color='red')
        ax2.tick_params(axis='y', labelcolor='red')
        
        # æ ‡è®°è¥é”€æŠ•æ”¾æœŸé—´
        campaign_periods = self.data[self.data['cm_flg'] == 1]['cdr_date']
        for date in campaign_periods:
            ax.axvline(x=date, color='green', alpha=0.3, linestyle='--')
        
        ax.set_xlabel('Date')
        ax.grid(True, alpha=0.3)
        
        # å›¾ä¾‹
        lines1, labels1 = ax.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
    
    def plot_marketing_effectiveness(self, ax):
        """ç»˜åˆ¶è¥é”€æ•ˆæœåˆ†æ"""
        ax.set_title('Marketing Campaign Effectiveness', fontweight='bold')
        
        if 'marketing' in self.insights:
            insights = self.insights['marketing']
            
            categories = ['No Campaign', 'Campaign Days']
            values = [insights['avg_acquisition_no_campaign'], 
                     insights['avg_acquisition_campaign']]
            colors = ['lightblue', 'orange']
            
            bars = ax.bar(categories, values, color=colors)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.1f}',
                       ha='center', va='bottom', fontweight='bold')
            
            # æ·»åŠ æå‡å¹…åº¦
            lift_text = f"Lift: {insights['relative_lift']:.1%}"
            ax.text(0.5, max(values) * 0.9, lift_text, 
                   transform=ax.transAxes, ha='center', 
                   fontsize=12, fontweight='bold', color='green')
            
            ax.set_ylabel('Avg Daily Acquisitions')
            ax.grid(True, alpha=0.3)
    
    def plot_service_patterns(self, ax):
        """ç»˜åˆ¶å®¢æœéœ€æ±‚æ¨¡å¼"""
        ax.set_title('Customer Service Demand Patterns', fontweight='bold')
        
        if 'customer_service' in self.insights:
            insights = self.insights['customer_service']
            
            weekdays = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
            pattern_values = [insights['weekly_pattern'].get(i, 1) for i in range(7)]
            
            bars = ax.bar(weekdays, pattern_values, 
                         color=['lightcoral' if x > 1.1 else 'lightblue' for x in pattern_values])
            
            # æ·»åŠ åŸºå‡†çº¿
            ax.axhline(y=1, color='black', linestyle='--', alpha=0.5, label='Average')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars, pattern_values):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{value:.2f}x',
                       ha='center', va='bottom', fontsize=10)
            
            ax.set_ylabel('Demand Multiplier')
            ax.legend()
            ax.grid(True, alpha=0.3)
    
    def plot_search_correlation(self, ax):
        """ç»˜åˆ¶æœç´¢è¶‹åŠ¿å…³è”"""
        ax.set_title('Search Trend vs Business Metrics', fontweight='bold')
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        valid_data = self.data.dropna(subset=['search_cnt', 'acc_get_cnt'])
        
        if len(valid_data) > 10:
            scatter = ax.scatter(valid_data['search_cnt'], valid_data['acc_get_cnt'], 
                               alpha=0.6, color='purple')
            
            # æ·»åŠ è¶‹åŠ¿çº¿
            if len(valid_data) > 2:
                z = np.polyfit(valid_data['search_cnt'], valid_data['acc_get_cnt'], 1)
                p = np.poly1d(z)
                ax.plot(valid_data['search_cnt'], p(valid_data['search_cnt']), 
                       "r--", alpha=0.8, linewidth=2)
            
            ax.set_xlabel('Search Volume')
            ax.set_ylabel('Account Acquisitions')
            
            # æ·»åŠ ç›¸å…³æ€§ä¿¡æ¯
            if 'search_correlation' in self.insights:
                corr = self.insights['search_correlation']['current_correlation']
                ax.text(0.05, 0.95, f'Correlation: {corr:.3f}', 
                       transform=ax.transAxes, fontsize=12, 
                       bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7))
        
        ax.grid(True, alpha=0.3)
    
    def plot_model_performance(self, ax):
        """ç»˜åˆ¶æ¨¡å‹è¡¨ç°"""
        ax.set_title('Prediction Model Performance', fontweight='bold')
        
        if 'prediction_models' in self.insights:
            models = []
            accuracies = []
            
            if 'call_prediction' in self.insights['prediction_models']:
                call_model = self.insights['prediction_models']['call_prediction']
                if 'model_score' in call_model:
                    models.append('Service Calls')
                    accuracies.append(call_model['model_score'])
            
            if 'account_prediction' in self.insights['prediction_models']:
                account_model = self.insights['prediction_models']['account_prediction']
                if 'model_score' in account_model:
                    models.append('Account Acquisition')
                    accuracies.append(account_model['model_score'])
            
            if models:
                bars = ax.bar(models, accuracies, color=['skyblue', 'lightgreen'])
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar in bars:
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width()/2., height,
                           f'{height:.3f}',
                           ha='center', va='bottom', fontweight='bold')
                
                ax.set_ylabel('RÂ² Score')
                ax.set_ylim(0, 1)
                ax.grid(True, alpha=0.3)
    
    def plot_key_metrics_summary(self, ax):
        """ç»˜åˆ¶å…³é”®æŒ‡æ ‡æ€»è§ˆ"""
        ax.set_title('Key Business Metrics Summary', fontweight='bold')
        
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        metrics = {
            'Avg Daily Acquisitions': self.data['acc_get_cnt'].mean(),
            'Avg Daily Service Calls': self.data['call_num'].mean(),
            'Campaign Days': self.data['cm_flg'].sum(),
            'Total Days': len(self.data)
        }
        
        # åˆ›å»ºè¡¨æ ¼æ˜¾ç¤º
        table_data = []
        for metric, value in metrics.items():
            if isinstance(value, float):
                table_data.append([metric, f"{value:.1f}"])
            else:
                table_data.append([metric, str(value)])
        
        # æ·»åŠ è¥é”€æå‡ä¿¡æ¯
        if 'marketing' in self.insights:
            lift = self.insights['marketing']['relative_lift']
            table_data.append(['Marketing Lift', f"{lift:.1%}"])
        
        # åˆ›å»ºè¡¨æ ¼
        table = ax.table(cellText=table_data,
                        colLabels=['Metric', 'Value'],
                        cellLoc='center',
                        loc='center',
                        colWidths=[0.7, 0.3])
        
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1.2, 2)
        
        # éšè—åæ ‡è½´
        ax.axis('off')

# 6. å•†ä¸šä»·å€¼é‡åŒ–ç±»
class BusinessValueQuantifier:
    def __init__(self, insights):
        self.insights = insights
    
    def calculate_marketing_value(self):
        """è®¡ç®—è¥é”€ä»·å€¼"""
        print("\nğŸ’° è¥é”€ä»·å€¼é‡åŒ–")
        print("=" * 40)
        
        if 'marketing' not in self.insights:
            print("âŒ ç¼ºå°‘è¥é”€åˆ†ææ•°æ®")
            return {}
        
        marketing = self.insights['marketing']
        
        # å‡è®¾å‚æ•°
        customer_ltv = 180000  # å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼ï¼ˆæ—¥å…ƒï¼‰
        daily_campaign_cost = 50000  # æ—¥è¥é”€æˆæœ¬
        
        # è®¡ç®—ä»·å€¼
        daily_incremental_customers = marketing['absolute_lift']
        daily_incremental_revenue = daily_incremental_customers * customer_ltv
        daily_roi = (daily_incremental_revenue - daily_campaign_cost) / daily_campaign_cost
        
        # å¹´åº¦ä»·å€¼
        annual_campaign_cost = daily_campaign_cost * 365
        annual_incremental_revenue = daily_incremental_revenue * 365
        annual_net_value = annual_incremental_revenue - annual_campaign_cost
        
        value_metrics = {
            'daily_incremental_customers': daily_incremental_customers,
            'daily_incremental_revenue': daily_incremental_revenue,
            'daily_roi': daily_roi,
            'annual_campaign_cost': annual_campaign_cost,
            'annual_incremental_revenue': annual_incremental_revenue,
            'annual_net_value': annual_net_value
        }
        
        print(f"ğŸ“Š æ—¥å¢é‡å®¢æˆ·: {daily_incremental_customers:.1f} ä¸ª")
        print(f"ğŸ“Š æ—¥å¢é‡æ”¶å…¥: Â¥{daily_incremental_revenue:,.0f}")
        print(f"ğŸ“Š æ—¥è¥é”€ROI: {daily_roi:.1%}")
        print(f"ğŸ“Š å¹´å‡€ä»·å€¼: Â¥{annual_net_value:,.0f}")
        
        return value_metrics
    
    def calculate_service_optimization_value(self):
        """è®¡ç®—å®¢æœä¼˜åŒ–ä»·å€¼"""
        print("\nğŸ“ å®¢æœä¼˜åŒ–ä»·å€¼é‡åŒ–")
        print("=" * 40)
        
        # å‡è®¾å‚æ•°
        current_annual_cost = 15000000  # å½“å‰å¹´åº¦å®¢æœæˆæœ¬
        avg_hourly_cost = 3000  # å¹³å‡å°æ—¶æˆæœ¬
        
        # åŸºäºé¢„æµ‹æ¨¡å‹çš„ä¼˜åŒ–æ½œåŠ›
        if 'prediction_models' in self.insights and 'call_prediction' in self.insights['prediction_models']:
            model_accuracy = self.insights['prediction_models']['call_prediction'].get('model_score', 0)
            
            # å‡è®¾é¢„æµ‹å‡†ç¡®ç‡æ¯æå‡10%ï¼Œå¯ä»¥èŠ‚çœ5%çš„æˆæœ¬
            cost_reduction_rate = min(0.25, model_accuracy * 0.3)  # æœ€é«˜25%
            
            annual_cost_savings = current_annual_cost * cost_reduction_rate
            
            # æœåŠ¡è´¨é‡æ”¹å–„ä»·å€¼
            service_improvement_value = current_annual_cost * 0.1
            
            total_value = annual_cost_savings + service_improvement_value
            
            value_metrics = {
                'current_annual_cost': current_annual_cost,
                'cost_reduction_rate': cost_reduction_rate,
                'annual_cost_savings': annual_cost_savings,
                'service_improvement_value': service_improvement_value,
                'total_annual_value': total_value,
                'model_accuracy': model_accuracy
            }
            
            print(f"ğŸ“Š å½“å‰å¹´åº¦æˆæœ¬: Â¥{current_annual_cost:,.0f}")
            print(f"ğŸ“Š æˆæœ¬èŠ‚çº¦ç‡: {cost_reduction_rate:.1%}")
            print(f"ğŸ“Š å¹´åº¦æˆæœ¬èŠ‚çº¦: Â¥{annual_cost_savings:,.0f}")
            print(f"ğŸ“Š æœåŠ¡æ”¹å–„ä»·å€¼: Â¥{service_improvement_value:,.0f}")
            print(f"ğŸ“Š æ€»å¹´åº¦ä»·å€¼: Â¥{total_value:,.0f}")
            
            return value_metrics
        else:
            print("âŒ ç¼ºå°‘é¢„æµ‹æ¨¡å‹æ•°æ®")
            return {}
    
    def generate_executive_summary(self):
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        print("\nğŸ“‹ æ‰§è¡Œæ‘˜è¦")
        print("=" * 50)
        
        # æ±‡æ€»æ‰€æœ‰ä»·å€¼
        marketing_value = self.calculate_marketing_value()
        service_value = self.calculate_service_optimization_value()
        
        total_annual_value = 0
        if marketing_value:
            total_annual_value += marketing_value.get('annual_net_value', 0)
        if service_value:
            total_annual_value += service_value.get('total_annual_value', 0)
        
        print(f"\nğŸ¯ å…³é”®å‘ç°:")
        
        if marketing_value:
            print(f"   â€¢ è¥é”€ROIå¯è¾¾ {marketing_value['daily_roi']:.1%}")
            print(f"   â€¢ å¹´åº¦è¥é”€å‡€ä»·å€¼ Â¥{marketing_value['annual_net_value']:,.0f}")
        
        if service_value:
            print(f"   â€¢ å®¢æœæˆæœ¬å¯èŠ‚çº¦ {service_value['cost_reduction_rate']:.1%}")
            print(f"   â€¢ å¹´åº¦å®¢æœä¼˜åŒ–ä»·å€¼ Â¥{service_value['total_annual_value']:,.0f}")
        
        print(f"\nğŸ’° æ€»å•†ä¸šä»·å€¼:")
        print(f"   â€¢ å¹´åº¦æ€»ä»·å€¼: Â¥{total_annual_value:,.0f}")
        print(f"   â€¢ 3å¹´ç´¯è®¡ä»·å€¼: Â¥{total_annual_value * 3:,.0f}")
        
        print(f"\nğŸš€ ä¼˜å…ˆå»ºè®®:")
        print(f"   1. ç«‹å³ä¼˜åŒ–è¥é”€æŠ•æ”¾ç­–ç•¥")
        print(f"   2. éƒ¨ç½²å®¢æœéœ€æ±‚é¢„æµ‹ç³»ç»Ÿ")
        print(f"   3. å»ºç«‹æ•°æ®ç›‘æ§ä½“ç³»")
        print(f"   4. æŠ•èµ„æ•°æ®ç§‘å­¦å›¢é˜Ÿ")
        
        return {
            'marketing_value': marketing_value,
            'service_value': service_value,
            'total_annual_value': total_annual_value
        }

# 7. ä¸»æ‰§è¡Œå‡½æ•°
def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    print("ğŸš€ å¼€å§‹POSä¸šåŠ¡æ•°æ®åˆ†æ...")
    
    # 1. æ•°æ®åŠ è½½
    loader = DataLoader()
    if not loader.load_all_data():
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
        return
    
    # 2. æ•°æ®è´¨é‡æ£€æŸ¥
    loader.check_data_quality()
    
    # 3. æ•°æ®é¢„å¤„ç†
    preprocessor = DataPreprocessor(loader.data)
    master_data = preprocessor.create_master_dataset()
    featured_data = preprocessor.create_features()
    
    # 4. ä¸šåŠ¡åˆ†æ
    analyzer = BusinessAnalyzer(featured_data)
    
    # æ‰§è¡Œå„é¡¹åˆ†æ
    marketing_insights = analyzer.analyze_marketing_effectiveness()
    service_insights = analyzer.analyze_customer_service_patterns()
    search_insights = analyzer.analyze_search_business_correlation()
    model_insights = analyzer.build_prediction_models()
    
    # 5. æ•°æ®å¯è§†åŒ–
    visualizer = BusinessVisualizer(featured_data, analyzer.insights)
    dashboard = visualizer.create_comprehensive_dashboard()
    
    # 6. å•†ä¸šä»·å€¼é‡åŒ–
    value_quantifier = BusinessValueQuantifier(analyzer.insights)
    business_value = value_quantifier.generate_executive_summary()
    
    print("\nâœ… åˆ†æå®Œæˆï¼")
    print("ğŸ“Š æ‰€æœ‰æ´å¯Ÿå’Œå»ºè®®å·²ç”Ÿæˆ")
    print("ğŸ’¡ è¯·æŸ¥çœ‹ä¸Šæ–¹çš„å¯è§†åŒ–å›¾è¡¨å’Œåˆ†æç»“æœ")
    
    return {
        'data': featured_data,
        'insights': analyzer.insights,
        'business_value': business_value,
        'dashboard': dashboard
    }

# 8. æ‰§è¡Œåˆ†æ
if __name__ == "__main__":
    results = main()
